# Roadmap & Checkâ€‘ins â€” FallÂ 2025

> **Course:** Vanderbilt **CSâ€‘3860â€‘01 Undergraduate Research** (3 credits) Â· **Instructor:** Prof. Taylor T. Johnson Â· **Student:** Arthur Hu  
> **Focus:** *PhysicalÂ AI Ã— (Spatial) Signal Temporal Logic (STL/STREL)* â€” monitor / softly enforce temporal & spatioâ€‘temporal specifications in physicsâ€‘ML (neural ODE/PDE) models.  
> **Standing meeting:** **Fridays 11:00** (adjust as the lab finalizes schedule; Zoom during construction).  
> **Effort target:** **6â€“9 hrs/week** (rule of thumb for 3 credits); **deliver a report** by semester end.

---

## 0) Objectives & deliverables (what â€œdoneâ€ means)

**Primary objective.** Build a **lean, reproducible** experimental stack that:
1) evaluates **physicsâ€‘ML frameworks** for PDE/ODE modeling on small demos;  
2) integrates **STL/STREL monitoring** (time + space) for **trainingâ€‘time penalties** and **evaluation**;  
3) yields **evidenceâ€‘backed recommendations** on frameworks, datasets, and spec patterns.

**Deliverables (graded artifacts).**
- ğŸ“˜ **Endâ€‘ofâ€‘semester report** (10â€“12 pages) â€” methods, results, tradeâ€‘offs, and recommendations. See `docs/report/outline.md` for structure.
- ğŸ“‚ **Openâ€‘source repo** â€” runnable scripts, configs, seeds, and brief docs; CPUâ€‘first (GPU optional). CI runs smoke tests.
- ğŸ§ª **Reproducible experiments** â€” ablations + figures; exact commands logged.
- ğŸ—’ï¸ **Sprint notes** â€” brief biâ€‘weekly summaries (`docs/sprint*_report.md`).

**Definition of Done (per experiment).**
- Tracked configs/seeds; results saved to `runs/`.  
- Training curves + **robustness (Ï)** curves; aggregate metrics; plots generated by `scripts/plot_ablations.py`.  
- **Spec library** (STL/STREL) with plainâ€‘English paraphrases and unit tests.  
- â€œWhat we learnedâ€ bullet list (1â€“2 paragraphs) + compute budget.

---

## 1) Scope & stacks (what we will compare)

### Physicsâ€‘ML frameworks (evaluate & pick one primary)
- **Neuromancer** â€” PyTorch differentiable programming for **parametric constrained optimization**, physicsâ€‘informed ID, and **differentiable predictive control**. Good docs; easy to pipe custom losses/monitors.  ([GitHub](https://github.com/pnnl/neuromancer), [Docs](https://pnnl.github.io/neuromancer/))  
- **NVIDIA PhysicsNeMo** â€” stateâ€‘ofâ€‘theâ€‘art **SciML** pipelines; strong **neural operators/PINNs**, scalable training; heavier install; GPUâ€‘leaning but has CPU paths.  ([GitHub](https://github.com/NVIDIA/physicsnemo))  
- **Bosch TorchPhysics** â€” light PyTorch library for **PINN/DeepRitz/DeepONet/FNO** PDEs; very fast to stand up new PDEs.  ([GitHub](https://github.com/boschresearch/torchphysics), [Docs](https://boschresearch.github.io/torchphysics/))

**Rationale.** Start with **Neuromancer** as primary (fast PyTorch loop + constraints); keep **TorchPhysics** for PDE variety; treat **PhysicsNeMo** as stretch when scaling operators or GPU. See `docs/framework_survey.md` for the full comparison.

### STL/STREL monitoring (time & space)
- **RTAMT** â€” STL robustness monitors; **offline & online (boundedâ€‘future)**; discrete & dense time; Python with optional C++ backend.  ([GitHub](https://github.com/nickovic/rtamt), 2025 overview: [arXiv](https://arxiv.org/abs/2501.18608))  
- **MoonLight (STREL)** â€” spatioâ€‘temporal **reach/escape** logic; Java engine with Python/Matlab interfaces; Python wrapper used for 2D fields.  ([GitHub](https://github.com/MoonLightSuite/moonlight), [Paper](https://arxiv.org/abs/2104.14333), [Journal](https://link.springer.com/article/10.1007/s10009-023-00710-5))  
- **SpaTiaL** â€” objectâ€‘centric spatial relations + simple planning; optional roboticsâ€‘style demos.  ([GitHub org](https://github.com/KTH-RPL-Planiacs), [API docs](https://kth-rpl-planiacs.github.io/SpaTiaL/))

### Prior art to emulate (loss shaping)
- **STLnet (NeurIPSÂ 2020)** â€” uses **robust STL semantics** as differentiable guidance for sequence models; inspires our â€œlogicâ€‘asâ€‘lossâ€ approach.  ([Paper](https://proceedings.neurips.cc/paper/2020/file/a7da6ba0505a41b98bd85907244c4c30-Paper.pdf), [Abstract](https://proceedings.neurips.cc/paper/2020/hash/a7da6ba0505a41b98bd85907244c4c30-Abstract.html))

---

## 2) Datasets / problem spaces (STLâ€‘ready)

We prioritize **small, CPUâ€‘friendly** tasks with clear temporal or spatioâ€‘temporal properties. Full details and more options in `docs/dataset_recommendations.md`.

**Pilot (T1).**
- **1D diffusion / 2D heat (synthetic)** â€” already scaffolded here; train fast; ideal for wiring endâ€‘toâ€‘end STL/STREL.  
  *Spec ideas:* safety bound `G_[0,T](uâ‰¤U_max)`, eventual cooling `F_[0,Ï„]G_[0,T](uâ‰¤U_safe)`, STREL containment of a hotspot region.  
- **Burgersâ€™ 1D (synthetic)** â€” nonlinearity adds challenge; use TorchPhysics.

**Tierâ€‘2.**
- **Air quality (UCI Beijing multiâ€‘site)** â€” multivariate time series with known temporal patterns; STL over thresholds and recovery.  
- **Traffic speeds (METRâ€‘LA / PEMSâ€‘BAY)** â€” gridâ€‘like spatioâ€‘temporal signals; test STREL reach/escape (congestion spread).

**Stretch.** PDEBench minis (advectionâ€‘diffusion) or small **Navierâ€“Stokes (FNO)** slices when GPU is available.

---

## 3) Integration plan (how specs enter training & eval)

1) **Monitoring.** Wrap RTAMT/MoonLight monitors with simple Python adapters:  
   `Ï = monitor(formula, signal)` returning **robustness** (â‰¥0 satisfy, <0 violate).  
2) **Loss shaping (soft enforcement).** Add **differentiable robustness** penalties:  
   - **Maxâ€‘margin:** `L_spec = ReLU(âˆ’Ï + Îµ)`;  
   - **Smoothing:** replace `min/max/âˆ¨/âˆ§` with **softmin/softmax** (temperature Ï„) for gradient flow;  
   - **Schedule:** increase weight `Î»_spec` and sharpen Ï„ over epochs.  
   *Inspired by STLnet.*
3) **Constraint optimization (optional).** Use augmented Lagrangian / penalty in **Neuromancer** to treat specs as soft constraints.  
4) **Evaluation.** Report **spec satisfaction rate** and **average robustness margin** (higher is better) on train/val/test; run **online** (boundedâ€‘future) monitors where relevant; keep offline evaluation as ground truth.  
5) **Spatial signals.** For 2D fields, map grids to MoonLight graphs (cellsÂ â†’ nodes; adjacencyÂ â†’ 4/8â€‘neighborhood with distances).

---

## 4) Milestones & calendar (weekâ€‘byâ€‘week)

> Dates use Mondayâ€“Sunday windows starting **OctÂ 06,Â 2025**. Weâ€™ll adapt as needed; meet **FridaysÂ 11:00**.

| Week | Dates | Goals & tangible outcomes |
| --- | --- | --- |
| **W1** | OctÂ 06â€“OctÂ 12 | âœ… Set up env (CPUâ€‘first); verify `scripts/check_env.py`. Reproduce **1D diffusion** w/ baseline loss; implement **RTAMT eval** (`scripts/eval_diffusion_rtamt.py`). Document two STL formulas. |
| **W2** | OctÂ 13â€“OctÂ 19 | Wire **differentiable STL loss** (softmin/softmax) into `train_diffusion_stl.py`; ablate `Î»_spec, Ï„`. Add plots via `scripts/plot_ablations.py`. |
| **W3** | OctÂ 20â€“OctÂ 26 | Bring up **2D heat + STREL** (`train_heat2d_strel.py`); define hotspot containment spec (`scripts/specs/contain_hotspot.mls`). Export MoonLight Python adapter + unit tests. |
| **W4** | OctÂ 27â€“NovÂ 02 | Expand to **TorchPhysics BurgersÂ 1D** (`train_burgers_torchphysics.py`); align monitoring API; add eval script for Burgers. |
| **W5** | NovÂ 03â€“NovÂ 09 | **Framework checkpoint** â€” run matching tasks in **Neuromancer** and **TorchPhysics**; record **accuracy vs robustness vs time/memory**. Draft the **Frameworks** section of the report. |
| **W6** | NovÂ 10â€“NovÂ 16 | **Candidate real data**: air quality (UCI) or small traffic slice. Define 2â€“3 STL patterns; run offline monitoring; prototype one training run (if time). |
| **W7** | NovÂ 17â€“NovÂ 23 | **Ablations**: vary spec sharpness (Ï„), penalty schedules, and noise. Generate Pareto curves (**task loss** â†” **robustness**). |
| **W8** | NovÂ 24â€“NovÂ 30 | **Stress tests**: OOD IC/BC, grid resolution changes. Start drafting **Results** + **Discussion**. (Short weekâ€”Thanksgiving.) |
| **W9** | DecÂ 01â€“DecÂ 07 | **Polish figures**, finalize narrative; rerun any flaky seeds; prepare **artifact instructions**. |
| **W10** | DecÂ 08â€“DecÂ 14 | **Final report** & repository freeze (tags, checksums). Dryâ€‘run reproducibility script; submit and present. |

**Checkâ€‘ins.** Brief agenda posted before Friday: blockers, decisions needed, nextâ€‘week plan. Keep a running log at the bottom of this file.

---

## 5) Metrics, efficiency, and reproducibility

**Metrics (report all with 95% CIs across â‰¥3 seeds).**
- Task error (L2/MAE); **robustness margin** (mean/median Ï); **% satisfied**; compute **costs** (wall time, peak RAM/VRAM).  
- For spatial tasks: regionâ€‘level robustness and **front width** / **containment radius**.

**Speed & resource tips (applied by default).**
- Prefer **CPUâ€‘friendly demos** (32â€‘bit floats, small grids: 1DÂ â‰¤Â 256, 2DÂ â‰¤Â 64Ã—64); vectorize; avoid Python loops in monitors.  
- **Cache** static operators (Laplacian kernels, neighbor indices). Preâ€‘allocate tensors; turn off grad where not needed.  
- Use PyTorch **amp** on GPU when available; otherwise set `torch.set_num_threads(k)` to avoid oversubscription.  
- Keep optional stacks behind `requirements-extra.txt`; lazyâ€‘import Java/Python bridges for MoonLight.  
- Continuous profiling: log epoch time & memory.

**Reproducibility.**
- Exact **env file** + pin optional deps; deterministic seeds; save **configs, checkpoints, and monitors** with versions.  
- CI runs a CPU smoke test (diffusion/heat) to catch regressions. See `docs/REPRODUCIBILITY.md`.

---

## 6) Risks & fallbacks

- **MoonLight friction (Java/Python bindings).** Fallback: STRELâ€‘like neighborhood specs via pureâ€‘PyTorch masks; or use MoonLight **offline** only.  
- **Online vs differentiability limits.** If online monitors break differentiability, keep **offline ground truth** and train with **smooth surrogates**.  
- **PhysicsNeMo install or compute heavy.** Keep as **evaluationâ€‘only** later; focus on Neuromancer/TorchPhysics.  
- **Realâ€‘data surprises.** If airâ€‘quality/traffic wrangling stalls, stay on synthetic PDEs and document transfer to real data.

---

## 7) Backlog (living)

- [ ] Add **traffic** toy grid + STREL spec (congestion not escaping ring).  
- [ ] Add **Grayâ€“Scott** reactionâ€‘diffusion mini demo.  
- [ ] Try **augmented Lagrangian** spec constraints in Neuromancer.  
- [ ] Explore **neural operators** (FNO/UNO) via PhysicsNeMo/TorchPhysics for faster PDE fields.  
- [ ] Draft a **dataset card** template for each task (signals, specs, eval).

---

## 8) Pointers (quick links)

- **Frameworks:** Neuromancer ([GH](https://github.com/pnnl/neuromancer), [Docs](https://pnnl.github.io/neuromancer/)); PhysicsNeMo ([GH](https://github.com/NVIDIA/physicsnemo)); TorchPhysics ([GH](https://github.com/boschresearch/torchphysics), [Docs](https://boschresearch.github.io/torchphysics/)).  
- **STL/STREL:** RTAMT ([GH](https://github.com/nickovic/rtamt), [arXivÂ 2025](https://arxiv.org/abs/2501.18608)); MoonLight/STREL ([GH](https://github.com/MoonLightSuite/moonlight), [arXivÂ 2021](https://arxiv.org/abs/2104.14333), [JournalÂ 2023](https://link.springer.com/article/10.1007/s10009-023-00710-5)); SpaTiaL ([GHÂ org](https://github.com/KTH-RPL-Planiacs), [API](https://kth-rpl-planiacs.github.io/SpaTiaL/)).  
- **Prior art:** STLnet (NeurIPSÂ 2020) ([paper](https://proceedings.neurips.cc/paper/2020/file/a7da6ba0505a41b98bd85907244c4c30-Paper.pdf), [abstract](https://proceedings.neurips.cc/paper/2020/hash/a7da6ba0505a41b98bd85907244c4c30-Abstract.html)).

---

## Running log (freeâ€‘form)

*Copy the template below for each week.*

**Date:** â€¦  
**Focus:** â€¦  
**What worked / blocked:** â€¦  
**Next:** â€¦

**Last updated:** SepÂ 30,Â 2025
