# physical-ai-stl

*A minimal, fast, and reproducible scaffold for experimenting with **Signal Temporal Logic (STL)** and **spatioâ€‘temporal logics (STREL/SpaTiaL)** on physicsâ€‘based ML models (a.k.a. â€œphysical AIâ€): neural ODE/PDE surrogates, PINNs/DeepONets/FNOs, and differentiable predictive control.*

> **Course context.** Built for **Vanderbilt CSâ€‘3860â€‘01 Undergraduate Research (FallÂ 2025)** with **Prof. Taylor Thomas Johnson**. Scope: prototype STL/STREL monitoring and (optionally) soft enforcement within physicsâ€‘aware ML frameworks; compare a few representative stacks; run on small, CPUâ€‘friendly demos; deliver a concise endâ€‘ofâ€‘semester report.

---

## ğŸ” Goals (what this repo is for)

1. **Evaluate 3 physicsâ€‘ML frameworks** on small PDE/ODE demos:
   - **Neuromancer** (PyTorch SciML; constrained optimization / PINNs / DPC)
   - **NVIDIA PhysicsNeMo** (exâ€‘Modulus; neural operators, PINNs; GPUâ€‘optimized but has CPUâ€‘only paths)
   - **Bosch TorchPhysics** (meshâ€‘free PINNs/DeepRitz/DeepONets/FNO)
2. **Wire up STL/STREL monitoring**:
   - **RTAMT** for STL (offline **and** online robustness; online supports boundedâ€‘future)
   - **MoonLight** for **STREL** (spatioâ€‘temporal reach/escape operators; Java engine + Python wrapper)
   - **SpaTiaL** for objectâ€‘centric spatioâ€‘temporal specs and simple planning/monitoring
3. **Prototype soft/differentiable STL penalties** to *nudge* models to satisfy specs (no hard guarantees).
4. **Recommend 2â€“3 problem spaces/datasets** (STLâ€‘friendly) and document integration points.
5. **Produce an endâ€‘ofâ€‘semester report** with methodology, results, and recommendations.

> **Weekly cadence per CSâ€‘3860**: ~**6â€“9 hrs/week** for **3 credits** (â‰ˆ2â€“3 hours per credit) and **group meeting Fridays 11:00** (Zoom/inâ€‘person per lab announcement). *Oneâ€‘page living plan + a final report are the required deliverables.*

---

## ğŸš€ Quickstart (CPUâ€‘only, lean & fast)

Requirements: **PythonÂ â‰¥Â 3.10**, macOS/Linux/WSL (Windows works; SpaTiaLâ€™s automatonâ€‘based planner is Linux/macOS only).

```bash
# 1) Create venv and install minimal runtime + dev test deps (tiny install)
python -m venv .venv && source .venv/bin/activate  # on Windows: .venv\Scripts\activate
python -m pip install -r requirements.txt -r requirements-dev.txt

# 2) (Optional) Install extras â€” STL/STREL + physicsâ€‘ML stacks (may pull PyTorch)
python -m pip install -r requirements-extra.txt
# If you want *CPU* PyTorch wheels only (to avoid CUDA downloads):
python -m pip install --index-url https://download.pytorch.org/whl/cpu torch

# 3) Smoke tests (safe: will *skip* if optional deps are missing)
pytest -q
# Or run a subset quickly:
pytest -q -k "hello or stl_soft or pde_example"

# (Optional) Makefile helpers:
make -n quickstart   # shows steps
make quickstart      # creates venv + installs + runs fast tests
```

**Docker (fully reproducible, CPU):**
```bash
# Build. WITH_EXTRAS=1 installs STL/STREL + physics stacks (best effort).
docker build --build-arg WITH_EXTRAS=1 -t physical-ai-stl:cpu .
# Run tests inside the container (mirrors CI)
docker run --rm -it physical-ai-stl:cpu
```

---

## ğŸ§­ Repository map

```
src/physical_ai_stl/
  frameworks/         # tiny â€œhelloâ€ demos for Neuromancer / PhysicsNeMo / TorchPhysics
  monitoring/         # RTAMT + MoonLight helpers (and differentiable STL â€˜stl_softâ€™)
  monitors/           # simple spec snippets (STL/STREL) for quick reuse
  datasets/           # small synthetic datasets (e.g., STLnetâ€‘style toy generator)
  experiments/        # 1D diffusion, 2D heat (minimal CPU demos)
  physics/            # PDE utilities for toy problems
  training/           # light train/eval scaffolding (grids, seeds)
tests/                # all tests are skipâ€‘aware for optional heavy deps
configs/, scripts/, docs/ (lightweight helpers)
```

**Design for speed & stability**
- *Lean base install* (`requirements.txt`) keeps CI and firstâ€‘run fast; heavy stacks live in `requirements-extra.txt`.
- *Optional dependency pattern* throughout (`pytest.importorskip`, lazy imports) lets tests pass even without extras.
- *CPUâ€‘byâ€‘default*; CUDA never autoâ€‘downloads. Torch CPU wheels are used unless you opt into GPU yourself.
- *Determinism* helpers (`utils/seed.py`) for reproducibility on small demos.

---

## ğŸ§ª What already runs (baseline demos)

All demos are tiny; expect seconds on CPU.

- **STL soft penalties** (`monitoring/stl_soft.py`) â€” smooth min/max & temporal ops; unit tests in `tests/test_stl_soft.py`.
- **RTAMT monitor â€œhelloâ€** (`monitors/rtamt_hello.py`) â€” evaluate `G_[a,b](u â‰¤ u_max)` on short traces; tested in `tests/test_rtamt_hello.py`.
- **MoonLight STREL â€œhelloâ€** (`monitors/moonlight_hello.py`, `monitors/moonlight_strel_hello.py`) â€” requires **JavaÂ 21+**; tests skip if missing.
- **SpaTiaL spec â€œhelloâ€** (`monitors/spatial_demo.py`) â€” Linux/macOS only for MONAâ€‘based planner; tests skip on Windows.
- **Framework smoke tests**:
  - `frameworks/neuromancer_hello.py` (`tests/test_neuromancer_hello.py`)
  - `frameworks/physicsnemo_hello.py` (`tests/test_physicsnemo_hello.py`)
  - `frameworks/torchphysics_hello.py` (`tests/test_torchphysics_hello.py`)
- **Toy PDEs**: 1D diffusion & 2D heat (`experiments/`, `physics/`) with monitors; see `tests/test_pde_example.py`, `tests/test_pde_robustness.py`.

> CI runs `pytest -q` on Ubuntu and only installs the *lean* deps. Optional stacks are tested locally/Docker.

---

## ğŸ§© Integration patterns (how STL/STREL ties in)

**A. Postâ€‘hoc monitoring** (zeroâ€‘risk):  
Run RTAMT (STL) and MoonLight (STREL) on model outputs and log *robustness* values. Use for dashboards, ablations, and safety thresholding.

**B. Soft constraints in training** (lightweight, differentiable, *no guarantees*):  
Use `stl_soft` to approximate STL robustness (smooth min/max via logâ€‘sumâ€‘exp / softplus), then add to loss:
- **Neuromancer**: plug robustness penalties into `nm.loss.PenaltyLoss` (naturally supports constrained training).  
- **TorchPhysics**: add STL penalty into the Lightning loss alongside PDE residuals.  
- **PhysicsNeMo**: add a callback/head computing soft robustness; aggregate into Hydraâ€‘configured loss.

**C. Spatial logic** (STREL/SpaTiaL):  
For PDE fields: encode properties like **â€œhotspot dissipates within T across the domainâ€** (STREL reach/escape).  
For object/sensor graphs: specify relations like **â€œno more than K sensors within radius R below speed threshold for >Î”tâ€** (SpaTiaL).

---

## ğŸ“š Frameworks & tooling at a glance

| Component | What it is (oneâ€‘liner) | Install notes |
|---|---|---|
| **Neuromancer** | PyTorch SciML library for constrained optimization, PINNs, DPC | `pip install neuromancer` or clone; docs & examples available. |
| **PhysicsNeMo** | NVIDIAâ€™s (exâ€‘Modulus) physicsâ€‘AI stack; neural operators/PINNs with Hydra tooling | `pip install nvidia-physicsnemo` (Sym addâ€‘on: `nvidia-physicsnemo-sym`); or use NGC container. |
| **TorchPhysics** | Meshâ€‘free PDE library with PINNs/DeepRitz/DeepONets/FNO | `pip install torchphysics` (needs PyTorchÂ â‰¥Â 2.0). |
| **RTAMT** | STL monitoring (offline & online; boundedâ€‘future online) with robustness semantics | `pip install rtamt` (optional C++ backend). |
| **MoonLight (STREL)** | Java engine + Python package for spatioâ€‘temporal monitoring (STREL) | `pip install moonlight` + **JavaÂ 21+** in PATH. |
| **SpaTiaL** | Spatioâ€‘temporal object relations + planning/monitoring | `pip install spatial-spec` (+ MONA/`ltlf2dfa`; Linux/macOS recommended). |

---

## ğŸ—ºï¸ Candidate problem spaces / datasets (STLâ€‘friendly)

Pick **one primary** + **one backup** early in the semester.

1) **Toy PDE fields (deterministic, tiny)** â€” *fastest path to results*  
   - **1D diffusion / 2D heat** with synthetic initial conditions.  
   - Example specs:  
     - `G_[0,T] (u(x,t) â‰¤ u_max)` (safety bound)  
     - `F_[0,T] G_[0,Ï„] (|âˆ‡u| â‰¤ L)` (eventual spatial smoothness)  
   - Runs entirely on CPU in seconds.

2) **2D Darcy flow (neural operator baseline)** â€” *PhysicsNeMo Sym example*  
   - Use FNO tutorial datasets (per docs) and monitor pressure/flux bounds or boundary conditions.  
   - Example specs: `G_[0,T] (p_max âˆ’ p(x,t) â‰¥ 0 âˆ§ p(x,t) âˆ’ p_min â‰¥ 0)`; `G_[0,T] (â€–âˆ‡pâ€– â‰¤ c)`.

3) **Urban sensor networks (traffic speed)** â€” *graph sensors, natural STREL*  
   - **METRâ€‘LA** (207 sensors, 5â€‘minute speeds, **MarÂ 1â€“JunÂ 30Â 2012**).  
   - **PEMSâ€‘BAY** (325 sensors, 5â€‘minute speeds, **JanÂ 1â€“MayÂ 31Â 2017**).  
   - Example specs: *No cascade:* **not**(â‰¥Â 10 sensors within 2â€‘hop radius below 20Â mph for â‰¥Â 15Â min);  
     *Bounded propagation:* congestion waves propagate slower than `v_max` across adjacency.

> Alternative: **Airâ€‘quality sensors** (e.g., PM2.5 city networks) with STREL â€œsurround/reachâ€ constraints (see STLnet and related smartâ€‘city work).  
> *Scaling option later:* **LargeST** (NeurIPSÂ 2023) provides statewide, longâ€‘horizon traffic with metadataâ€”use only after core pipeline is proven on small sets.

---

## ğŸ—“ï¸ Suggested semester plan (draft)

- **WeeksÂ 1â€“2**: Environment ready; run all â€œhelloâ€ tests; short evaluation notes for the 3 frameworks + 3 logic toolchains.  
- **WeeksÂ 3â€“4**: Choose **primary dataset**; reproduce a tiny baseline (e.g., Darcy FNO tutorial or diffusion PINN). Define **2â€“3 specs**.  
- **WeeksÂ 5â€“6**: Postâ€‘hoc monitoring + plots; sensitivity to spec thresholds.  
- **WeeksÂ 7â€“9**: Add **soft STL penalties** in training; ablations vs. baselines (accuracy, robustness).  
- **WeeksÂ 10â€“12**: Add **spatial** specs (MoonLight/SpaTiaL) for the chosen domain.  
- **WeekÂ 13+**: Polish figures, **final report**, and repository artifacts.

**Deliverables**
- *Running code & configs* for one primary experiment;  
- *Short written report* (problem, specs, methods, results, discussion, limits);  
- *Comparison table* for stacks & tooling;  
- *Reproducibility checklist* (env, seed, dataset pointers).

---

## ğŸ”§ Usage snippets

**Evaluate an STL spec on a short trace with RTAMT**
```python
from physical_ai_stl.monitoring.rtamt_monitor import stl_always_upper_bound, evaluate_series
spec = stl_always_upper_bound("u", u_max=1.0)   # G(u <= 1.0)
rob  = evaluate_series(spec, "u", [0.2, 0.4, 1.1], dt=1.0)  # -> negative means violation magnitude
```

**Soft STL penalty in training (frameworkâ€‘agnostic)**
```python
from physical_ai_stl.monitoring import stl_soft as S
# Soft robustness: G_[0,T] (u <= umax)
def soft_G_always_leq(u, umax):
    return S.soft_min(umax - u)   # vectorized; larger is better; negative violates

penalty = (-soft_G_always_leq(u_pred, umax)).relu().mean()  # add to loss
```

> These â€œsoftâ€ semantics are differentiable approximations for convenience; they **do not** provide formal guarantees.

---

## ğŸ§± Reproducibility & performance tips

- Prefer **CPU** runs first; turn on GPU only after correctness.  
- For MoonLight (STREL), ensure **JavaÂ 21+** is installed and on `PATH`.  
- SpaTiaL relies on **MONA/ltlf2dfa** and is best on Linux/macOS (its automaton planner is skipped on Windows in tests).  
- Keep datasets **small** (e.g., 16â€“64Â² grids, 100â€“500 samples) for rapid iteration; scale later.  
- Use `pytest -q -k ...` to run focused subsets; CI mirrors this minimal footprint.

---

## ğŸ§¾ References (primary docs & datasets)

- **Neuromancer** â€” Repo & docs (features, install, examples).  
  - GitHub: https://github.com/pnnl/neuromancer  
  - Docs: https://pnnl.github.io/neuromancer/

- **NVIDIA PhysicsNeMo** â€” Repo & install guide (exâ€‘Modulus; CPU/GPU; tutorials e.g., **Darcy FNO**).  
  - GitHub: https://github.com/NVIDIA/physicsnemo  
  - Install: https://docs.nvidia.com/physicsnemo/latest/getting-started/installation.html  
  - Darcy FNO tutorial: https://docs.nvidia.com/physicsnemo/latest/physicsnemo-sym/user_guide/neural_operators/darcy_fno.html

- **TorchPhysics** â€” Repo & docs (PINNs/DeepRitz/DeepONets/FNO).  
  - GitHub: https://github.com/boschresearch/torchphysics  
  - Docs: https://boschresearch.github.io/torchphysics/

- **RTAMT** â€” STL monitoring (robustness; boundedâ€‘future online).  
  - GitHub: https://github.com/nickovic/rtamt  
  - PyPI: https://pypi.org/project/rtamt/

- **MoonLight (STREL)** â€” Java engine + Python package; **requires JavaÂ 21+**.  
  - GitHub: https://github.com/MoonLightSuite/moonlight

- **SpaTiaL** â€” Spatioâ€‘temporal specifications; Linux/macOS recommended (MONA/`ltlf2dfa`).  
  - GitHub: https://github.com/KTH-RPL-Planiacs/SpaTiaL  
  - PyPI: https://pypi.org/project/spatial-spec/

- **STLnet** â€” NeurIPSÂ 2020 paper enforcing STL in sequence models; relevant for STLâ€‘guided training ideas.  
  - Abstract/PDF: https://proceedings.neurips.cc/paper/2020/file/a7da6ba0505a41b98bd85907244c4c30-Paper.pdf  
  - Code: https://github.com/meiyima/STLnet

- **Physics datasets** (starter options)  
  - **PDEBench** (NeurIPSÂ 2022 benchmark + data): https://github.com/pdebench/PDEBench  
  - **FNO datasets** (Burgers/Darcy/NS): https://github.com/li-Pingan/fourier-neural-operator

- **Traffic datasets** (sensor networks)  
  - **METRâ€‘LA**: description & files (207 sensors, Marâ€“JunÂ 2012): https://www.kaggle.com/datasets/annnnguyen/metr-la-dataset  
  - **PEMSâ€‘BAY**: summary (325 sensors, Janâ€“MayÂ 2017): https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets_in_tsl.html  
  - **LargeST (NeurIPSÂ 2023)**: paper & code:  
    - Paper: https://proceedings.neurips.cc/paper_files/paper/2023/file/ee57cd73a76bd927ffca3dda1dc3b9d4-Paper-Datasets_and_Benchmarks.pdf  
    - Repo: https://github.com/liuxu77/LargeST

---

## ğŸ“ Contributing / issues

PRs and issues welcome (tests are fast and skip optional stacks automatically). Please:
- keep base installs lean; gate heavy deps behind `requirements-extra.txt`;
- add tests (`pytest`) and short docs for new monitors/experiments.

---

## ğŸ“„ License & citation

- **MIT License** (see [LICENSE](LICENSE)).  
- If you use this scaffold, please cite via **[CITATION.cff](CITATION.cff)**.

> Acknowledgments: thanks to Prof. Taylor T. Johnson for guidance on **physical AI** directions and to the Neuromancer, PhysicsNeMo, TorchPhysics, RTAMT, MoonLight, and SpaTiaL communities for their openâ€‘source work.
