# ========================================================================
# physical-ai-stl — .env.example
# ------------------------------------------------------------------------
# Copy this file to `.env` and `source .env` before running local scripts.
# This file is *safe* to use on laptops and CI, and keeps runs reproducible.
#
# Priorities:
#   1) Meet course needs (Neuromancer / PhysicsNeMo / TorchPhysics +
#      RTAMT / MoonLight / SpaTiaL) out-of-the-box on CPU.
#   2) Be fast and resource efficient by default; scale up only when asked.
#   3) Be tidy and portable across macOS/Linux/WSL (Windows: use PowerShell
#      equivalents like `$Env:VAR="..."` instead of `export`). 
# ========================================================================

# --- Repository import path ------------------------------------------------
# Make the local src/ package importable without installation.
export PYTHONPATH="$(pwd)/src:${PYTHONPATH}"

# --- Numerics & threading (safe defaults for laptops/CI) -------------------
# Keep BLAS/OpenMP threads in check to avoid oversubscription.
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
# Optional: pin OpenMP behavior a bit more (comment out if it hurts perf).
# export OMP_PROC_BIND=TRUE
# export OMP_PLACES=cores
# export OMP_WAIT_POLICY=ACTIVE

# --- Python runtime hygiene ------------------------------------------------
# Reproducibility: make hashing stable across processes.
export PYTHONHASHSEED=${PYTHONHASHSEED:-0}
# More helpful tracebacks if something crashes.
export PYTHONFAULTHANDLER=1
# Headless plotting by default (safe for SSH/CI).
export MPLBACKEND=${MPLBACKEND:-Agg}

# --- PyTorch / device knobs (all optional) ---------------------------------
# Prefer CPU by default; uncomment to force CPU-only PyTorch wheels.
# export PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"
# Choose a CUDA device when you have a GPU (comma-separated for multi-GPU).
# export CUDA_VISIBLE_DEVICES=0
# Apple Silicon: allow fallback when ops are missing on MPS.
export PYTORCH_ENABLE_MPS_FALLBACK=${PYTORCH_ENABLE_MPS_FALLBACK:-1}
# Determinism on NVIDIA GPUs (read once at CUDA init).
# Use small workspace to reduce memory; set to ':4096:8' for larger convs.
export CUBLAS_WORKSPACE_CONFIG=${CUBLAS_WORKSPACE_CONFIG:-:16:8}
# Optional: keep cuDNN from auto-tuning for speed (safer for determinism).
# export CUDNN_BENCHMARK=0

# --- Local caches & outputs ------------------------------------------------
# Keep tooling caches local to the repo to avoid polluting $HOME on shared
# machines (safe to delete any time).
export XDG_CACHE_HOME="${XDG_CACHE_HOME:-$(pwd)/.cache}"
export TORCH_HOME="${TORCH_HOME:-$XDG_CACHE_HOME/torch}"
export HF_HOME="${HF_HOME:-$XDG_CACHE_HOME/huggingface}"
# Central place for run artifacts (scripts respect these if present).
export DATA_ROOT="${DATA_ROOT:-$(pwd)/data}"
export RESULTS_DIR="${RESULTS_DIR:-$(pwd)/results}"
export LOG_DIR="${LOG_DIR:-$(pwd)/logs}"

# --- MoonLight (STREL) -----------------------------------------------------
# If you install MoonLight (Java required), point to a JDK or let your
# system's `java` be found on PATH. For CI or hermetic setups you can set:
# export JAVA_HOME="/path/to/jdk"
# export PATH="$JAVA_HOME/bin:$PATH"
# Modest default heap; adjust if you hit OutOfMemoryError.
export JDK_JAVA_OPTIONS="${JDK_JAVA_OPTIONS:--Xmx2g -Xms256m}"
# Demo spec path used by monitors/moonlight_strel_hello.py (optional override).
export PHYSICAL_AI_STL_MLS_PATH="${PHYSICAL_AI_STL_MLS_PATH:-$(pwd)/scripts/specs/contain_hotspot.mls}"

# --- Repo power-user toggles (lazy by default) -----------------------------
# Eagerly import physics helpers (useful for IDEs; harmless otherwise).
# export PHYSICAL_AI_STL_EAGER_IMPORTS=1
# Fail fast if a forwarded helper is missing (implies eager imports).
# export PHYSICAL_AI_STL_STRICT_INIT=1

# --- Logging noise control -------------------------------------------------
# Quieter numpy/scipy warnings; comment out if you want full verbosity.
export PYTHONWARNINGS=${PYTHONWARNINGS:-"ignore"}
# Torch logs: set to "WARNING" or "INFO" to debug numerical issues.
export TORCH_CPP_LOG_LEVEL=${TORCH_CPP_LOG_LEVEL:-"ERROR"}

# --- Quality-of-life -------------------------------------------------------
# Make tools prefer UTF-8 across locales.
export LC_ALL=${LC_ALL:-C.UTF-8}
export LANG=${LANG:-C.UTF-8}

# --- Notes -----------------------------------------------------------------
# • Windows (PowerShell): use `$Env:VAR="..."` instead of `export VAR=...`.
# • Determinism: scripts call utils.seed.seed_everything(...) which respects
#   CUBLAS_WORKSPACE_CONFIG and friends. Environment values set *here* take
#   effect as long as they are exported before Python imports torch.
# • You can always override any variable inline, e.g.:
#       CUBLAS_WORKSPACE_CONFIG=:4096:8 python scripts/run_experiment.py
# ========================================================================
